{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptive statistics from the dataset\n",
    "\n",
    "# def desc_stats(df):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to prepare the dataset into desired form\n",
    "\n",
    "def data_prep(data):\n",
    "    df = pd.read_csv(data)\n",
    "    df = df.drop(columns=[\"INDICATOR\",\"FLAG\"])\n",
    "    # Getting all the categorical variables\n",
    "    # categorical_variables = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    # numerical_variables = df.select_dtypes(include=['number']).columns.tolist()\n",
    "    # Check if there are any null values in the DataFrame\n",
    "    if df.isnull().values.any():\n",
    "    # Remove rows with any null values\n",
    "        df = df.dropna()\n",
    "    df = df.drop(columns=[\"PANEL_NUM\",\"UNIT_NUM\",\"STUB_NAME_NUM\",\"STUB_LABEL_NUM\",\"YEAR_NUM\",\"AGE_NUM\",\"STUB_NAME\"])\n",
    "\n",
    "    # Create the Gender column\n",
    "    df['GENDER'] = df['STUB_LABEL'].apply(lambda x: 'Male' if 'Male' in x else 'Female' if 'Female' in x else 'Unknown')\n",
    "\n",
    "    # Creating are you hispanic latino column \n",
    "    df['HISPANIC_LATINO_FLAG'] = df['STUB_LABEL'].apply(\n",
    "            lambda x: 0 if  'Female: Not Hispanic or Latino: American Indian or Alaska Native' in x\n",
    "            or 'Female: Not Hispanic or Latino: Black' in x\n",
    "            or 'Female: Not Hispanic or Latino: White' in x\n",
    "            or 'Male: Not Hispanic or Latino: American Indian or Alaska Native' in x\n",
    "            or 'Male: Not Hispanic or Latino: Black' in x\n",
    "            or 'Male: Not Hispanic or Latino: White' in x\n",
    "            or 'Male: Not Hispanic or Latino: Asian or Pacific Islander' in x\n",
    "            or 'Female: Not Hispanic or Latino: Asian or Pacific Islander' in x\n",
    "            or 'Male: Not Hispanic or Latino: Asian' in x\n",
    "            or 'Male: Not Hispanic or Latino: Native Hawaiian or Other Pacific Islander' in x\n",
    "            or 'Female: Not Hispanic or Latino: Asian' in x\n",
    "            or 'Female: Not Hispanic or Latino: Native Hawaiian or Other Pacific Islander' in x        \n",
    "            else 1)\n",
    "\n",
    "    df['HISPANIC_LATINO_RACE'] = df['STUB_LABEL'].apply(lambda x: 1 if 'Male: Hispanic or Latino: All races' in x or 'Female: Hispanic or Latino: All races' in x else 0)\n",
    "\n",
    "    df['WHITE'] = df['STUB_LABEL'].apply(lambda x: 1 if 'Female: White' in x \n",
    "                                        or 'Male: White' in x \n",
    "                                        or 'Female: Not Hispanic or Latino: White' in x \n",
    "                                        or 'Male: Not Hispanic or Latino: White' in x\n",
    "                                        else 0)\n",
    "\n",
    "    df['NATIVE_BLACK'] = df['STUB_LABEL'].apply(lambda x: 1 if 'Female: Not Hispanic or Latino: Black' in x \n",
    "                                        or 'Male: Not Hispanic or Latino: Black' in x\n",
    "                                        else 0)\n",
    "\n",
    "    df['BLACK_AMERICAN'] = df['STUB_LABEL'].apply(lambda x: 1 if 'Female: Black or African American' in x \n",
    "                                        or 'Male: Black or African American' in x\n",
    "                                        else 0)\n",
    "\n",
    "    df['AMERICAN_INDIAN'] = df['STUB_LABEL'].apply(lambda x: 1 if 'Female: Not Hispanic or Latino: American Indian or Alaska Native' in x \n",
    "                                        or 'Male: Not Hispanic or Latino: American Indian or Alaska Native' in x\n",
    "                                        or 'Male: American Indian or Alaska Native' in x\n",
    "                                        or 'Female: American Indian or Alaska Native' in x\n",
    "                                        else 0)\n",
    "\n",
    "    df['ASIAN_PACIFIC_ISLANDER'] = df['STUB_LABEL'].apply(lambda x: 1 if 'Male: Asian or Pacific Islander' in x \n",
    "                                        or 'Female: Asian or Pacific Islander' in x\n",
    "                                        or 'Male: Not Hispanic or Latino: Asian or Pacific Islander' in x\n",
    "                                        or 'Female: Not Hispanic or Latino: Asian or Pacific Islander' in x\n",
    "                                        else 0)\n",
    "\n",
    "    df['ASIAN'] = df['STUB_LABEL'].apply(lambda x: 1 if 'Male: Not Hispanic or Latino: Asian' in x \n",
    "                                        or 'Female: Not Hispanic or Latino: Asian' in x\n",
    "                                        else 0)\n",
    "\n",
    "    df['NATIVE_HAWAIIAN'] = df['STUB_LABEL'].apply(lambda x: 1 if 'Male: Not Hispanic or Latino: Native Hawaiian or Other Pacific Islander' in x \n",
    "                                        or 'Female: Not Hispanic or Latino: Native Hawaiian or Other Pacific Islander' in x\n",
    "                                        else 0)\n",
    "\n",
    "    word_map = {\n",
    "    \"All drug overdose deaths\": \"All\",\n",
    "    \"Drug overdose deaths involving any opioid\": \"Any_Opioid\",\n",
    "    \"Drug overdose deaths involving natural and semisynthetic opioids\": \"Natural_Opioids\",\n",
    "    \"Drug overdose deaths involving other synthetic opioids (other than methadone)\": \"Other_Synthetic\",\n",
    "    \"Drug overdose deaths involving methadone\": \"Methadone\",\n",
    "    \"Drug overdose deaths involving heroin\": \"Heroin\"\n",
    "    }\n",
    "    # Replace values in the 'Panel' column with one-word representations\n",
    "    df[\"PANEL\"] = df[\"PANEL\"].replace(word_map)\n",
    "    df['PANEL'].value_counts()\n",
    "\n",
    "    word_map2 = {\n",
    "        \"Deaths per 100,000 resident population, crude\": \"Crude\",\n",
    "        \"Deaths per 100,000 resident population, age-adjusted\": \"Age_Adjusted\",\n",
    "    }\n",
    "    # Replace values in the 'Unit' column with one-word representations\n",
    "    df[\"UNIT\"] = df[\"UNIT\"].replace(word_map2)\n",
    "\n",
    "    df = df.drop(columns=\"STUB_LABEL\")\n",
    "\n",
    "    #Print a list of categorical variables\n",
    "    categorical_variables2 = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "    # Perform one-hot encoding on 'STUB_LABEL' column\n",
    "    df_encoded = pd.get_dummies(df, columns=categorical_variables2)\n",
    "\n",
    "    # Convert all boolean columns to integer columns with 1 and 0\n",
    "    bool_cols = df_encoded.select_dtypes(include='bool').columns\n",
    "    df_encoded[bool_cols] = df_encoded[bool_cols].astype(int)\n",
    "\n",
    "    # Change column names to lowercase and replace spaces with underscores\n",
    "    df_encoded.columns = df_encoded.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "    df_encoded = df_encoded.drop(columns=[\"panel_all\",\"age_all_ages\",\"gender_unknown\"])\n",
    "\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Variable\"] = df_encoded.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(df_encoded.values, i) for i in range(df_encoded.shape[1])]\n",
    "\n",
    "    # print(vif_data)\n",
    "\n",
    "    df = df_encoded.drop(columns=[\"unit_age_adjusted\",\"unit_crude\"])\n",
    "\n",
    "    return df_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = data_prep('Drug_overdose_death_rates__by_drug_type__sex__age__race__and_Hispanic_origin__United_States_20240518.csv')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>estimate</th>\n",
       "      <th>hispanic_latino_flag</th>\n",
       "      <th>hispanic_latino_race</th>\n",
       "      <th>white</th>\n",
       "      <th>native_black</th>\n",
       "      <th>black_american</th>\n",
       "      <th>american_indian</th>\n",
       "      <th>asian_pacific_islander</th>\n",
       "      <th>asian</th>\n",
       "      <th>...</th>\n",
       "      <th>age_25-34_years</th>\n",
       "      <th>age_35-44_years</th>\n",
       "      <th>age_45-54_years</th>\n",
       "      <th>age_55-64_years</th>\n",
       "      <th>age_65-74_years</th>\n",
       "      <th>age_75-84_years</th>\n",
       "      <th>age_85_years_and_over</th>\n",
       "      <th>age_under_15_years</th>\n",
       "      <th>gender_female</th>\n",
       "      <th>gender_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001</td>\n",
       "      <td>6.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  estimate  hispanic_latino_flag  hispanic_latino_race  white  \\\n",
       "0  1999       6.1                     1                     0      0   \n",
       "1  2000       6.2                     1                     0      0   \n",
       "2  2001       6.8                     1                     0      0   \n",
       "3  2002       8.2                     1                     0      0   \n",
       "4  2003       8.9                     1                     0      0   \n",
       "\n",
       "   native_black  black_american  american_indian  asian_pacific_islander  \\\n",
       "0             0               0                0                       0   \n",
       "1             0               0                0                       0   \n",
       "2             0               0                0                       0   \n",
       "3             0               0                0                       0   \n",
       "4             0               0                0                       0   \n",
       "\n",
       "   asian  ...  age_25-34_years  age_35-44_years  age_45-54_years  \\\n",
       "0      0  ...                0                0                0   \n",
       "1      0  ...                0                0                0   \n",
       "2      0  ...                0                0                0   \n",
       "3      0  ...                0                0                0   \n",
       "4      0  ...                0                0                0   \n",
       "\n",
       "   age_55-64_years  age_65-74_years  age_75-84_years  age_85_years_and_over  \\\n",
       "0                0                0                0                      0   \n",
       "1                0                0                0                      0   \n",
       "2                0                0                0                      0   \n",
       "3                0                0                0                      0   \n",
       "4                0                0                0                      0   \n",
       "\n",
       "   age_under_15_years  gender_female  gender_male  \n",
       "0                   0              0            0  \n",
       "1                   0              0            0  \n",
       "2                   0              0            0  \n",
       "3                   0              0            0  \n",
       "4                   0              0            0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_iterations(df_encoded, cols_to_drop=None):\n",
    "    if cols_to_drop is not None:\n",
    "        df_encoded = df_encoded.drop(columns=cols_to_drop)\n",
    "    # Preprocess the data\n",
    "    X = df_encoded.drop('estimate', axis=1)  # Features\n",
    "    y = df_encoded['estimate']  # Target variable\n",
    "\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create and train the Random Forest model\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = mse ** 0.5\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Random Forest Regressor \\n\")\n",
    "    if cols_to_drop is not None:\n",
    "        print('columns dropped are: ',cols_to_drop)\n",
    "    else:\n",
    "        print('no columns are dropped')\n",
    "    print(f'Root Mean Squared Error: {rmse:.2f}')\n",
    "    print(f'R-squared: {r2:.2f}')   \n",
    "\n",
    "    # Create and train the Gradient Boosting Regressor\n",
    "    gb_regressor = GradientBoostingRegressor(n_estimators=100, max_depth=3, random_state=42)\n",
    "    gb_regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = gb_regressor.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(f\"\\nGradient Boosting Regressor \\n\")\n",
    "    if cols_to_drop is not None:\n",
    "        print('columns dropped are: ',cols_to_drop)\n",
    "    else:\n",
    "        print('no columns are dropped')\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f'Mean Squared Error: {mse:.2f}')\n",
    "    print(f'R-squared: {r2:.2f}')\n",
    "\n",
    "    # Create and train the Linear Regression model\n",
    "    lin_regressor = LinearRegression()\n",
    "    lin_regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = lin_regressor.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(f\"\\nLinear Regression\\n\")\n",
    "    if cols_to_drop is not None:\n",
    "        print('columns dropped are: ',cols_to_drop)\n",
    "    else:\n",
    "        print('no columns are dropped')\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f'Mean Squared Error: {mse:.2f}')\n",
    "    print(f'R-squared: {r2:.2f}')\n",
    "\n",
    "    # Create and fit the logistic regression model\n",
    "    logistic_model = LogisticRegression()\n",
    "    logistic_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions and evaluate the model\n",
    "    y_pred = logistic_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    auc_roc = roc_auc_score(y_test, logistic_model.predict_proba(X_test)[:, 1])\n",
    "    print(f'Accuracy: {accuracy:.2f}, AUC-ROC: {auc_roc:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor \n",
      "\n",
      "no columns are dropped\n",
      "Root Mean Squared Error: 1.33\n",
      "R-squared: 0.96\n",
      "\n",
      "Gradient Boosting Regressor \n",
      "\n",
      "no columns are dropped\n",
      "Mean Squared Error: 12.98\n",
      "R-squared: 0.96\n",
      "\n",
      "Linear Regression\n",
      "\n",
      "no columns are dropped\n",
      "Mean Squared Error: 14.02\n",
      "R-squared: 0.96\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel_iterations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_cleaned\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[55], line 67\u001b[0m, in \u001b[0;36mmodel_iterations\u001b[1;34m(df_encoded, cols_to_drop)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Create and fit the logistic regression model\u001b[39;00m\n\u001b[0;32m     66\u001b[0m logistic_model \u001b[38;5;241m=\u001b[39m LogisticRegression()\n\u001b[1;32m---> 67\u001b[0m \u001b[43mlogistic_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Make predictions and evaluate the model\u001b[39;00m\n\u001b[0;32m     70\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m logistic_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:1209\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1199\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[0;32m   1201\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m   1202\u001b[0m     X,\n\u001b[0;32m   1203\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1207\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39msolver \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1208\u001b[0m )\n\u001b[1;32m-> 1209\u001b[0m \u001b[43mcheck_classification_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1210\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n\u001b[0;32m   1212\u001b[0m multi_class \u001b[38;5;241m=\u001b[39m _check_multi_class(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_class, solver, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\multiclass.py:221\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    213\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m ]:\n\u001b[1;32m--> 221\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Maybe you are trying to fit a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier, which expects discrete classes on a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression target with continuous values.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    225\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values."
     ]
    }
   ],
   "source": [
    "model_iterations(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
