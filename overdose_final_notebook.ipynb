{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to prepare the dataset into desired form\n",
    "\n",
    "def data_prep(data):\n",
    "    df = pd.read_csv(data)\n",
    "    df = df.drop(columns=[\"INDICATOR\",\"FLAG\"])\n",
    "    # Getting all the categorical variables\n",
    "    # categorical_variables = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    # numerical_variables = df.select_dtypes(include=['number']).columns.tolist()\n",
    "    # Check if there are any null values in the DataFrame\n",
    "    if df.isnull().values.any():\n",
    "    # Remove rows with any null values\n",
    "        df = df.dropna()\n",
    "    df = df.drop(columns=[\"PANEL_NUM\",\"UNIT_NUM\",\"STUB_NAME_NUM\",\"STUB_LABEL_NUM\",\"YEAR_NUM\",\"AGE_NUM\",\"STUB_NAME\"])\n",
    "\n",
    "    # Create the Gender column\n",
    "    df['GENDER'] = df['STUB_LABEL'].apply(lambda x: 'Male' if 'Male' in x else 'Female' if 'Female' in x else 'Unknown')\n",
    "\n",
    "    # Creating are you hispanic latino column \n",
    "    df['HISPANIC_LATINO_FLAG'] = df['STUB_LABEL'].apply(\n",
    "            lambda x: 0 if  'Female: Not Hispanic or Latino: American Indian or Alaska Native' in x\n",
    "            or 'Female: Not Hispanic or Latino: Black' in x\n",
    "            or 'Female: Not Hispanic or Latino: White' in x\n",
    "            or 'Male: Not Hispanic or Latino: American Indian or Alaska Native' in x\n",
    "            or 'Male: Not Hispanic or Latino: Black' in x\n",
    "            or 'Male: Not Hispanic or Latino: White' in x\n",
    "            or 'Male: Not Hispanic or Latino: Asian or Pacific Islander' in x\n",
    "            or 'Female: Not Hispanic or Latino: Asian or Pacific Islander' in x\n",
    "            or 'Male: Not Hispanic or Latino: Asian' in x\n",
    "            or 'Male: Not Hispanic or Latino: Native Hawaiian or Other Pacific Islander' in x\n",
    "            or 'Female: Not Hispanic or Latino: Asian' in x\n",
    "            or 'Female: Not Hispanic or Latino: Native Hawaiian or Other Pacific Islander' in x        \n",
    "            else 1)\n",
    "\n",
    "    df['HISPANIC_LATINO_RACE'] = df['STUB_LABEL'].apply(lambda x: 1 if 'Male: Hispanic or Latino: All races' in x or 'Female: Hispanic or Latino: All races' in x else 0)\n",
    "\n",
    "    df['WHITE'] = df['STUB_LABEL'].apply(lambda x: 1 if 'Female: White' in x \n",
    "                                        or 'Male: White' in x \n",
    "                                        or 'Female: Not Hispanic or Latino: White' in x \n",
    "                                        or 'Male: Not Hispanic or Latino: White' in x\n",
    "                                        else 0)\n",
    "\n",
    "    df['NATIVE_BLACK'] = df['STUB_LABEL'].apply(lambda x: 1 if 'Female: Not Hispanic or Latino: Black' in x \n",
    "                                        or 'Male: Not Hispanic or Latino: Black' in x\n",
    "                                        else 0)\n",
    "\n",
    "    df['BLACK_AMERICAN'] = df['STUB_LABEL'].apply(lambda x: 1 if 'Female: Black or African American' in x \n",
    "                                        or 'Male: Black or African American' in x\n",
    "                                        else 0)\n",
    "\n",
    "    df['AMERICAN_INDIAN'] = df['STUB_LABEL'].apply(lambda x: 1 if 'Female: Not Hispanic or Latino: American Indian or Alaska Native' in x \n",
    "                                        or 'Male: Not Hispanic or Latino: American Indian or Alaska Native' in x\n",
    "                                        or 'Male: American Indian or Alaska Native' in x\n",
    "                                        or 'Female: American Indian or Alaska Native' in x\n",
    "                                        else 0)\n",
    "\n",
    "    df['ASIAN_PACIFIC_ISLANDER'] = df['STUB_LABEL'].apply(lambda x: 1 if 'Male: Asian or Pacific Islander' in x \n",
    "                                        or 'Female: Asian or Pacific Islander' in x\n",
    "                                        or 'Male: Not Hispanic or Latino: Asian or Pacific Islander' in x\n",
    "                                        or 'Female: Not Hispanic or Latino: Asian or Pacific Islander' in x\n",
    "                                        else 0)\n",
    "\n",
    "    df['ASIAN'] = df['STUB_LABEL'].apply(lambda x: 1 if 'Male: Not Hispanic or Latino: Asian' in x \n",
    "                                        or 'Female: Not Hispanic or Latino: Asian' in x\n",
    "                                        else 0)\n",
    "\n",
    "    df['NATIVE_HAWAIIAN'] = df['STUB_LABEL'].apply(lambda x: 1 if 'Male: Not Hispanic or Latino: Native Hawaiian or Other Pacific Islander' in x \n",
    "                                        or 'Female: Not Hispanic or Latino: Native Hawaiian or Other Pacific Islander' in x\n",
    "                                        else 0)\n",
    "\n",
    "    word_map = {\n",
    "    \"All drug overdose deaths\": \"All\",\n",
    "    \"Drug overdose deaths involving any opioid\": \"Any_Opioid\",\n",
    "    \"Drug overdose deaths involving natural and semisynthetic opioids\": \"Natural_Opioids\",\n",
    "    \"Drug overdose deaths involving other synthetic opioids (other than methadone)\": \"Other_Synthetic\",\n",
    "    \"Drug overdose deaths involving methadone\": \"Methadone\",\n",
    "    \"Drug overdose deaths involving heroin\": \"Heroin\"\n",
    "    }\n",
    "    # Replace values in the 'Panel' column with one-word representations\n",
    "    df[\"PANEL\"] = df[\"PANEL\"].replace(word_map)\n",
    "    df['PANEL'].value_counts()\n",
    "\n",
    "    word_map2 = {\n",
    "        \"Deaths per 100,000 resident population, crude\": \"Crude\",\n",
    "        \"Deaths per 100,000 resident population, age-adjusted\": \"Age_Adjusted\",\n",
    "    }\n",
    "    # Replace values in the 'Unit' column with one-word representations\n",
    "    df[\"UNIT\"] = df[\"UNIT\"].replace(word_map2)\n",
    "\n",
    "    df = df.drop(columns=\"STUB_LABEL\")\n",
    "\n",
    "    #Print a list of categorical variables\n",
    "    categorical_variables2 = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "    # Perform one-hot encoding on 'STUB_LABEL' column\n",
    "    df_encoded = pd.get_dummies(df, columns=categorical_variables2)\n",
    "\n",
    "    # Convert all boolean columns to integer columns with 1 and 0\n",
    "    bool_cols = df_encoded.select_dtypes(include='bool').columns\n",
    "    df_encoded[bool_cols] = df_encoded[bool_cols].astype(int)\n",
    "\n",
    "    # Change column names to lowercase and replace spaces with underscores\n",
    "    df_encoded.columns = df_encoded.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "    df_encoded = df_encoded.drop(columns=[\"panel_all\",\"age_all_ages\",\"gender_unknown\"])\n",
    "\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Variable\"] = df_encoded.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(df_encoded.values, i) for i in range(df_encoded.shape[1])]\n",
    "\n",
    "    # print(vif_data)\n",
    "\n",
    "    df_encoded = df_encoded.drop(columns=[\"unit_age_adjusted\",\"unit_crude\"])\n",
    "\n",
    "    return df_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = data_prep('Drug_overdose_death_rates__by_drug_type__sex__age__race__and_Hispanic_origin__United_States_20240518.csv')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>estimate</th>\n",
       "      <th>hispanic_latino_flag</th>\n",
       "      <th>hispanic_latino_race</th>\n",
       "      <th>white</th>\n",
       "      <th>native_black</th>\n",
       "      <th>black_american</th>\n",
       "      <th>american_indian</th>\n",
       "      <th>asian_pacific_islander</th>\n",
       "      <th>asian</th>\n",
       "      <th>...</th>\n",
       "      <th>age_25-34_years</th>\n",
       "      <th>age_35-44_years</th>\n",
       "      <th>age_45-54_years</th>\n",
       "      <th>age_55-64_years</th>\n",
       "      <th>age_65-74_years</th>\n",
       "      <th>age_75-84_years</th>\n",
       "      <th>age_85_years_and_over</th>\n",
       "      <th>age_under_15_years</th>\n",
       "      <th>gender_female</th>\n",
       "      <th>gender_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001</td>\n",
       "      <td>6.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  estimate  hispanic_latino_flag  hispanic_latino_race  white  \\\n",
       "0  1999       6.1                     1                     0      0   \n",
       "1  2000       6.2                     1                     0      0   \n",
       "2  2001       6.8                     1                     0      0   \n",
       "3  2002       8.2                     1                     0      0   \n",
       "4  2003       8.9                     1                     0      0   \n",
       "\n",
       "   native_black  black_american  american_indian  asian_pacific_islander  \\\n",
       "0             0               0                0                       0   \n",
       "1             0               0                0                       0   \n",
       "2             0               0                0                       0   \n",
       "3             0               0                0                       0   \n",
       "4             0               0                0                       0   \n",
       "\n",
       "   asian  ...  age_25-34_years  age_35-44_years  age_45-54_years  \\\n",
       "0      0  ...                0                0                0   \n",
       "1      0  ...                0                0                0   \n",
       "2      0  ...                0                0                0   \n",
       "3      0  ...                0                0                0   \n",
       "4      0  ...                0                0                0   \n",
       "\n",
       "   age_55-64_years  age_65-74_years  age_75-84_years  age_85_years_and_over  \\\n",
       "0                0                0                0                      0   \n",
       "1                0                0                0                      0   \n",
       "2                0                0                0                      0   \n",
       "3                0                0                0                      0   \n",
       "4                0                0                0                      0   \n",
       "\n",
       "   age_under_15_years  gender_female  gender_male  \n",
       "0                   0              0            0  \n",
       "1                   0              0            0  \n",
       "2                   0              0            0  \n",
       "3                   0              0            0  \n",
       "4                   0              0            0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'estimate', 'hispanic_latino_flag', 'hispanic_latino_race',\n",
       "       'white', 'native_black', 'black_american', 'american_indian',\n",
       "       'asian_pacific_islander', 'asian', 'native_hawaiian',\n",
       "       'panel_any_opioid', 'panel_heroin', 'panel_methadone',\n",
       "       'panel_natural_opioids', 'panel_other_synthetic', 'age_15-24_years',\n",
       "       'age_25-34_years', 'age_35-44_years', 'age_45-54_years',\n",
       "       'age_55-64_years', 'age_65-74_years', 'age_75-84_years',\n",
       "       'age_85_years_and_over', 'age_under_15_years', 'gender_female',\n",
       "       'gender_male'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_iterations(df_encoded, cols_to_drop=None):\n",
    "    if cols_to_drop is not None:\n",
    "        df_encoded = df_encoded.drop(columns=cols_to_drop)\n",
    "    # Preprocess the data\n",
    "    X = df_encoded.drop('estimate', axis=1)  # Features\n",
    "    y = df_encoded['estimate']  # Target variable\n",
    "\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create and train the Random Forest model\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = mse ** 0.5\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Random Forest Regressor \\n\")\n",
    "    if cols_to_drop is not None:\n",
    "        print('columns dropped are: ',cols_to_drop)\n",
    "    else:\n",
    "        print('no columns are dropped')\n",
    "    print(f'Root Mean Squared Error: {rmse:.2f}')\n",
    "    print(f'R-squared: {r2:.2f}')   \n",
    "\n",
    "    # Assume 'model' is your trained model object\n",
    "    # Serialize the model object\n",
    "    with open('model.pkl', 'wb') as file:\n",
    "        pickle.dump(rf_model, file)\n",
    "\n",
    "    # Create and train the Gradient Boosting Regressor\n",
    "    gb_regressor = GradientBoostingRegressor(n_estimators=100, max_depth=3, random_state=42)\n",
    "    gb_regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = gb_regressor.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(f\"\\nGradient Boosting Regressor \\n\")\n",
    "    if cols_to_drop is not None:\n",
    "        print('columns dropped are: ',cols_to_drop)\n",
    "    else:\n",
    "        print('no columns are dropped')\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f'Mean Squared Error: {mse:.2f}')\n",
    "    print(f'R-squared: {r2:.2f}')\n",
    "\n",
    "    # Create and train the Linear Regression model\n",
    "    lin_regressor = LinearRegression()\n",
    "    lin_regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = lin_regressor.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(f\"\\nLinear Regression\\n\")\n",
    "    if cols_to_drop is not None:\n",
    "        print('columns dropped are: ',cols_to_drop)\n",
    "    else:\n",
    "        print('no columns are dropped')\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f'Mean Squared Error: {mse:.2f}')\n",
    "    print(f'R-squared: {r2:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor \n",
      "\n",
      "no columns are dropped\n",
      "Root Mean Squared Error: 1.33\n",
      "R-squared: 0.96\n",
      "\n",
      "Gradient Boosting Regressor \n",
      "\n",
      "no columns are dropped\n",
      "Mean Squared Error: 12.98\n",
      "R-squared: 0.96\n",
      "\n",
      "Linear Regression\n",
      "\n",
      "no columns are dropped\n",
      "Mean Squared Error: 14.03\n",
      "R-squared: 0.96\n"
     ]
    }
   ],
   "source": [
    "model_iterations(df_cleaned)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
